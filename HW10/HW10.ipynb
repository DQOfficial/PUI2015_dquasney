{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#HW 10 CLUSTERING BUSINESS\n",
    "\n",
    "###Dan Quasney"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#cluster time trends in NYC businesses: \n",
    "#DATA\n",
    "#Census Business data:\n",
    "##download census data for businesses by ZIP code. the data is here\n",
    "http://www.census.gov/econ/cbp/download/\n",
    "##and it can be downloaded by hand. you can also download it with 3 terminal commands as follows: the data from 1993 through 2001 is different in the format of its path than the data after 2001 (that is why more than one for loop is needed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile \n",
    "import pandas as pd\n",
    "import glob\n",
    "import urllib2\n",
    "import json\n",
    "import pylab as pl\n",
    "import sklearn.cluster\n",
    "import os\n",
    "import scipy \n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kelly_colors_hex = [\n",
    "    '#FFB300', # Vivid Yellow\n",
    "    '#803E75', # Strong Purple\n",
    "    '#FF6800', # Vivid Orange\n",
    "    '#A6BDD7', # Very Light Blue\n",
    "    '#C10020', # Vivid Red\n",
    "    '#CEA262', # Grayish Yellow\n",
    "    '#817066', # Medium Gray\n",
    "    '#007D34', # Vivid Green\n",
    "    '#F6768E', # Strong Purplish Pink\n",
    "    '#00538A', # Strong Blue\n",
    "    '#FF7A5C', # Strong Yellowish Pink\n",
    "    '#53377A', # Strong Violet\n",
    "    '#FF8E00', # Vivid Orange Yellow\n",
    "    '#B32851', # Strong Purplish Red\n",
    "    '#F4C800', # Vivid Greenish Yellow\n",
    "    '#7F180D', # Strong Reddish Brown\n",
    "    '#93AA00', # Vivid Yellowish Green\n",
    "    '#593315', # Deep Yellowish Brown\n",
    "    '#F13A13', # Vivid Reddish Orange\n",
    "    '#232C16', # Dark Olive Green\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Task 1: Data Cleaning and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'zbp94totals.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-ced892c70125>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m94\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mfile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'zbp{0}totals.zip'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mzippy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzippy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.zip'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Dan\\Anaconda\\lib\\zipfile.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, file, mode, compression, allowZip64)\u001b[0m\n\u001b[0;32m    754\u001b[0m             \u001b[0mmodeDict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'r'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'a'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;34m'r+b'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    755\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 756\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    757\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'a'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'zbp94totals.zip'"
     ]
    }
   ],
   "source": [
    "# read in zip files and then store them in a new dictionary\n",
    "dict={}\n",
    "for i in range (94,100):\n",
    "    file_name = 'zbp{0}totals.zip'.format(i)\n",
    "    zippy = zipfile.ZipFile(file_name)\n",
    "    dict[i] = pd.read_csv(zippy.open(file_name.replace('.zip','.txt')))\n",
    "    \n",
    "    for i in range (0,10):\n",
    "        file_name = 'zbp0{0}totals.zip'.format(i)\n",
    "        zippy = zipfile.ZipFile(fname)\n",
    "        df[i] = pd.read_csv(zippy.open(file_name.replace('.zip','.txt')))\n",
    "                \n",
    "    for i in range (10,14):\n",
    "        file_name = 'zbp{0}totals.zip'.format(i)\n",
    "        zippy = zipfile.ZipFile(fname)\n",
    "        dict[i] = pd.read_csv(zippy.open(file_name.replace('.zip','.txt')))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'read_file'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-6de28a802ef4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgeopandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'nyc-zip-code-tabulation-areas-polygons.geojson'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mnyc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mnyc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'module' object has no attribute 'read_file'"
     ]
    }
   ],
   "source": [
    "import geopandas as gp\n",
    "file_name = 'nyc-zip-code-tabulation-areas-polygons.geojson'\n",
    "nyc = gp.read_file(fname)\n",
    "nyc.plot(figsize=(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create an index of the years as a list\n",
    "new_index = dict.keys()\n",
    "# convert to lower case\n",
    "for i in new_index: \n",
    "    k = [x.lower() for x in (dict[i].columns.tolist())]\n",
    "    dict[i].columns = k\n",
    "#print dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict1 = {}\n",
    "for i in new_index:\n",
    "    dict1[i] = dict1[i][['zip', 'est']]\n",
    "    dict1[i]['year'] = i\n",
    "#dict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d0 = pd.DataFrame(df1[0])\n",
    "\n",
    "for i in index[1:]:\n",
    "    d3 = pd.DataFrame(dict1[i])\n",
    "    d0 = np.concatenate((d0, d3), axis=0)\n",
    "data = pd.DataFrame(d0, columns = ['zip','est','year'])\n",
    "print data.shape\n",
    "print data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = \"https://nycdatastables.s3.amazonaws.com/2013-08-19T18:18:28.877Z/nyc-zip-code-tabulation-areas-polygons.geojson\"\n",
    "req = urllib2.urlopen(url)\n",
    "nyc_zipcodes = json.load(req)\n",
    "nyc_zip = []\n",
    "for dept in nyc_zipcodes['features']:\n",
    "    nyc_zip.append(str(dept['properties'][\"postalCode\"]))\n",
    "print nyc_zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "table = data['zip'].isin(nyc_zip)\n",
    "data = data[table]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-7cdc0991be7b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgroup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'year'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'zip'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#group.head()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "group = data.groupby(['year','zip']).mean().unstack()\n",
    "#group.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_data = group['est']\n",
    "final_data.to_csv('final_data.csv')\n",
    "final_data = pd.read_csv('final_data.csv')\n",
    "# define list of years:\n",
    "year = np.arange(1994, 2014, 1).tolist()\n",
    "\n",
    "final_data['year'] = ['2000','2001','2002','2003','2004','2005','2006','2007',\n",
    "                 '2008','2009','2010', '2011','2012','2013','1994','1995','1996','1997','1998','1999']\n",
    "final_data.index = final_data['year']\n",
    "del final_data['year']\n",
    "\n",
    "final=final_data.sort_index()\n",
    "final.to_csv('final.csv')\n",
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final = pd.read_csv('final.csv')\n",
    "final.index = final['year'].values\n",
    "del final['year']\n",
    "final = final.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final.dropna()\n",
    "final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final =final.dropna()\n",
    "\n",
    "zipcode = final.index.tolist()\n",
    "final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pl.figure(figsize=(20,5))\n",
    "plt.xlim(1994,2013)\n",
    "\n",
    "for i in range(len(final)):\n",
    "    plt.plot(final.iloc[i],alpha=0.5)\n",
    "    \n",
    "pl.ylabel(\"Growth in Business Establishments\", fontsize=14)\n",
    "pl.xlabel(\"Year\", fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Task 2: K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-140dc295e1a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0meuclid_dist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mt2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'final' is not defined"
     ]
    }
   ],
   "source": [
    "x = final.values\n",
    "\n",
    "def euclid_dist(t1,t2):\n",
    "    return np.sqrt(sum((t1-t2)**2))\n",
    "\n",
    "import random\n",
    "\n",
    "def k_means_clust(data,num_clust,num_iter):\n",
    "    centroids=random.sample(data,num_clust)\n",
    "    counter=0\n",
    "    for n in range(num_iter):\n",
    "        counter+=1\n",
    "        print counter\n",
    "        holder={}\n",
    "        \n",
    "        # assign points to clusters\n",
    "        for ind,i in enumerate(data):\n",
    "            min_dist=float('inf')\n",
    "            closest_clust=None\n",
    "            for c_ind,j in enumerate(centroids):\n",
    "                if euclid_dist(i,j)<min_dist:\n",
    "                    min_dist = euclid_dist(i,j)\n",
    "                    closest_clust=c_ind\n",
    "            if closest_clust in holder:\n",
    "                holder[closest_clust].append(ind)\n",
    "            else:\n",
    "                holder[closest_clust]=[]\n",
    "    \n",
    "        # then recalculate centroids of clusters\n",
    "        for key in holder:\n",
    "            clust_sum=0\n",
    "            for k in holder[key]:\n",
    "                clust_sum=clust_sum+data[k]\n",
    "            centroids[key]=[m/len(holder[key]) for m in clust_sum]\n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-a8d3182de223>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcentroids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mk_means_clust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mholder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#assign data points to clusters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mind\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'final' is not defined"
     ]
    }
   ],
   "source": [
    "x = final.values\n",
    "centroids=k_means_clust(x,2,10)\n",
    "holder={}\n",
    "#assign data points to clusters\n",
    "for ind,i in enumerate(x):\n",
    "    min_dist=float('inf')\n",
    "    closest_clust=None\n",
    "    for c_ind,j in enumerate(centroids):\n",
    "        if euclid_dist(i,j)<min_dist:\n",
    "            min_dist = euclid_dist(i,j)\n",
    "            closest_clust=c_ind\n",
    "    if closest_clust in holder:\n",
    "        holder[closest_clust].append(ind)\n",
    "    else:\n",
    "        holder[closest_clust]=[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'assignments' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-1507dd9f76ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcluster\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0massignments\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mcluster\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcluster\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcluster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'assignments' is not defined"
     ]
    }
   ],
   "source": [
    "cluster = pd.Series(0)\n",
    "for i,key in holder.iteritems():\n",
    "    for j in key:\n",
    "        cluster[j] = i\n",
    "cluster = cluster.sort_index()\n",
    "mydata = pd.DataFrame({'zip':zipcode,'cluster':cluster})\n",
    "zips = str(mydata.iloc[i]['zip'])\n",
    "cluster = mydata.iloc[i]['cluster']\n",
    "\n",
    "fig = plt.figure(figsize=(10,20))\n",
    "ax = []\n",
    "for i in range(len(centroids)):\n",
    "    ax.append(fig.add_subplot(5,1,i+1)) \n",
    "for i in range(len(mydata)):\n",
    "    cluster = mydata.iloc[i]['cluster']\n",
    "    ax[cluster].plot(final.iloc[i],'k',alpha=0.3)\n",
    "for i in range(len(centroids)):    \n",
    "    ax[i].plot(year,centroids[i],linewidth=10)\n",
    "\n",
    "\n",
    "map = pd.merge(nyc, mydata, left_on = 'postalCode', right_on = 'zip')\n",
    "map.plot(column='cluster', figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-68881f0ab2b2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcentroids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mk_means_clust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0massignments\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#assign data points to clusters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mind\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'final' is not defined"
     ]
    }
   ],
   "source": [
    "x = final.values\n",
    "centroids=k_means_clust(x,5,10)\n",
    "holder={}\n",
    "#assign data points to clusters\n",
    "for ind,i in enumerate(x):\n",
    "    min_dist=float('inf')\n",
    "    closest_clust=None\n",
    "    for c_ind,j in enumerate(centroids):\n",
    "        if euclid_dist(i,j)<min_dist:\n",
    "            min_dist = euclid_dist(i,j)\n",
    "            closest_clust=c_ind\n",
    "    if closest_clust in holder:\n",
    "        holder[closest_clust].append(ind)\n",
    "    else:\n",
    "        holder[closest_clust]=[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'holder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-7a76c32bfa08>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcluster\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mholder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mcluster\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcluster\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcluster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'holder' is not defined"
     ]
    }
   ],
   "source": [
    "cluster = pd.Series(0)\n",
    "for i,key in holder.iteritems():\n",
    "    for j in key:\n",
    "        cluster[j] = i\n",
    "cluster = cluster.sort_index()\n",
    "mydata = pd.DataFrame({'zip':zipcode,\n",
    "                       'cluster':cluster})\n",
    "zips = str(mydata.iloc[i]['zip'])\n",
    "cluster = mydata.iloc[i]['cluster']\n",
    "\n",
    "fig = plt.figure(figsize=(10,20))\n",
    "ax = []\n",
    "for i in range(len(centroids)):\n",
    "    ax.append(fig.add_subplot(5,1,i+1)) \n",
    "for i in range(len(mydata)):\n",
    "    cluster = mydata.iloc[i]['cluster']\n",
    "    ax[cluster].plot(final.iloc[i],'k',alpha=0.3)\n",
    "for i in range(len(centroids)):    \n",
    "    ax[i].plot(year,centroids[i],linewidth=10)\n",
    "\n",
    "map = pd.merge(nyc, mydata, left_on = 'postalCode', right_on = 'zip')\n",
    "map.plot(column='cluster', figsize=(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-means Cluster Evaluation: Silhouette Score\n",
    "\n",
    "\n",
    "The \"Silhouette Score\", S, which measures intra-cluster similarity, helps us determine the correct number of clusters to use. A score of 1 means that all observations fall perfectly within their respective cluster centroids, or that there is zero variance for all clusters.\n",
    "\n",
    "An S value near zero denotes that the clustering method is unstable or inappropriate for the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-fc30c2ce9238>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mkmeans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_clusters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_init\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mkmeans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'final' is not defined"
     ]
    }
   ],
   "source": [
    "# calculate the S value\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "# let's start with two clusters and then increase.\n",
    "k = 2\n",
    "kmeans = KMeans(n_clusters = k, n_init = 100)\n",
    "kmeans.fit(final)\n",
    "\n",
    "S = np.zeros(8)\n",
    "for k in range(0, 8):\n",
    "    est = KMeans(n_clusters = k+2, n_init = 100)\n",
    "    est.fit(final)\n",
    "    S[k] = silhouette_score(final, est.labels_)\n",
    "    print('At {0} clusters, silhouette score is {1}'.format(k+2, s[k]))\n",
    "    \n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar(range(2, 10), S)\n",
    "plt.xlabel('k', fontsize = 16)\n",
    "plt.ylabel('S Value', fontsize = 16)\n",
    "plt.title('Silhouette Score', fontsize = 20)\n",
    "plt.ylim(.2, .4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###The Silhouette Score tells us that five clusters is best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###DBScan Cluster\n",
    "\n",
    "Other clustering algorithm. Easy to implement and performed better than K-means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first calculate distance matrix\n",
    "dist_mat = pd.DataFrame(np.zeros(shape=(len(final),len(final))))\n",
    "for i in range(len(final)):\n",
    "    for j in range(len(final)):\n",
    "        dist_mat.iloc[i][j] = euclid_dist(final.iloc[i],final.iloc[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "db = DBSCAN(metric=\"precomputed\",eps=2).fit(dist_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = (db.labels_).astype(int)\n",
    "num_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "print('Number of clusters: %d' % num_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster = db.labels_+2\n",
    "nyczip = final.index.tolist()\n",
    "mydata = pd.DataFrame({'zip':nyczip,\n",
    "                       'cluster':cluster})\n",
    "mydata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map = pd.merge(nyc, mydata, left_on = 'postalCode', right_on = 'zip')\n",
    "map.plot(column='cluster', figsize=(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation\n",
    "\n",
    "The cluster analysis showed the considerable spatial difference in business growth between zip codes in the city. Through 2004 to 2013, the Midtown area of Manhattan underwent particularly slow growth, likely the result of the economic downturn and aftershock of 9/11 (perhaps not, but this behavior in the data is not surprising). This pattern persists when running the algorithm with different numbers of clusters as well, implying that it is an actual trend and not a false positive of sorts yielded by the method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#NYC zip codes shape file is here\n",
    "##http://data.nycprepared.org/dataset/nyc-zip-code-tabulation-areas/resource/0c0e14e9-78e1-404e-97b0-c2fabceb3981\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "TASKS:\n",
    "    \n",
    "    1. get and prep your data.\n",
    "    2. cluster the NUMBER OF ESTABLISHMENTS time series with K-means in **a few** clusters (as discussed there is no real good, sound way to decide what a good number is here. try a few options, keeping in mind a few is more than a couple, but i recommand you stay within the single digit numbers)\n",
    "    3. plot the cluster centers (if you used K means those are the means of the clusters). you can plot for example the cluster centers overlayed on each time series (using the alpha channel to control the opacity in the plot may be helpful here).\n",
    "    4. Use another clustering algorithm (of your choice)\n",
    "    5. overlay your data on a NYC map: you can use shapefiles for the zip codes and different colors for different clusters\n",
    "    6. Compare the results of the 2 algorithms\n",
    "    7. attempt an interpretation. this is dangerous ground: clustering is an exploratory tool so you do not want to jump to conclusions because you see some clusters! but seeing structure in your data can inform your next moves as an investigator. \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
